{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1485db86-15cf-4cb0-b5e3-e545f5e378b6",
   "metadata": {},
   "source": [
    "# Document Classification model training\n",
    "- We are creating a small REST service that can make class predictions on provided documents.\n",
    "- The service is hosted in Flask elsewhere, using a model we will train here.\n",
    "- The data provided by Trellis is a collection of about 1000 sample documents with classes already provided.\n",
    "- There is also a small number of documents outside the set of classes, so a response of \"other\" may be expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6697c11-76ab-4deb-b643-fd3eb79b7780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.19 (main, Mar 21 2024, 12:08:14) \n",
      "[Clang 14.0.6 ]\n",
      "1.4.3\n",
      "1.21.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "print(sys.version)\n",
    "print(pd.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b078f34c-85ab-43c5-9b7f-63ff3ea289ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Games firms 'face tough future'\\n\\nUK video ga...</td>\n",
       "      <td>technologie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>California sets fines for spyware\\n\\nThe maker...</td>\n",
       "      <td>technologie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T-Mobile bets on 'pocket office'\\n\\nT-Mobile h...</td>\n",
       "      <td>technologie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OnePlus 8 full specs comparison chart: 8 vs. 8...</td>\n",
       "      <td>technologie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Friends fear' with lost mobiles\\n\\nPeople are...</td>\n",
       "      <td>technologie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        label\n",
       "0  Games firms 'face tough future'\\n\\nUK video ga...  technologie\n",
       "1  California sets fines for spyware\\n\\nThe maker...  technologie\n",
       "2  T-Mobile bets on 'pocket office'\\n\\nT-Mobile h...  technologie\n",
       "3  OnePlus 8 full specs comparison chart: 8 vs. 8...  technologie\n",
       "4  'Friends fear' with lost mobiles\\n\\nPeople are...  technologie"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset provided by Trellis\n",
    "# Structure as given: subdirectories of text files.  Each subdirectory name also serves as a class label\n",
    "# There is a small collection of documents with the class 'other': the model should also make a separate prediction\n",
    "# if a document doesn't readily fit into any of the given labels.  It's not part of the training data, just a very small\n",
    "# sample for testing purposes, and obviously not representative of every other document out there.\n",
    "\n",
    "data = []   # array of (text, label) tuples\n",
    "\n",
    "root_path = \"Data\"\n",
    "labels = os.listdir(root_path)\n",
    "for label in labels:\n",
    "    subdir_path = os.path.join(root_path, label)\n",
    "    files = os.listdir(subdir_path)\n",
    "    for f in files:\n",
    "        full_path = os.path.join(subdir_path, f)\n",
    "        with open( full_path, 'r', encoding='utf-8' ) as f_in:\n",
    "            text = f_in.read()\n",
    "        row = ( text, label )\n",
    "        data.append(row)\n",
    "\n",
    "# convert data to dataframe\n",
    "df = pd.DataFrame(data, columns=['text', 'label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded4008e-cc25-493e-b97c-bbcc4a2a43db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep for NLP work\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75791015-0761-49cb-a32b-97ad197bfee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(doc:str) -> str:\n",
    "    \"\"\" Prep text for feature building\n",
    "        remove numbers, punctuation\n",
    "        remove stop words\n",
    "        lemmatization\n",
    "    \"\"\"\n",
    "    doc = re.sub(r'\\d+', '', doc)  # remove numbers\n",
    "    doc = re.sub(r'[^\\s\\w]', '', doc)   # keep only non-punctuation, whitespace\n",
    "    doc = doc.replace('\\n', '')  # some newlines accidentally escaped as a literal '\\n'\n",
    "    \n",
    "    # let spaCy work on stop words, lemmatization\n",
    "    doc_spacy = nlp(doc)\n",
    "\n",
    "    non_stop = [token.lemma_ for token in doc_spacy if not token.is_stop]\n",
    "    doc = ' '.join(non_stop)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7dde029-02b0-46a9-abb3-0a1b4efde9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>technologie</td>\n",
       "      <td>game firm face tough futureUK video game firm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>technologie</td>\n",
       "      <td>California set fine spywarethe maker computer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>technologie</td>\n",
       "      <td>tmobile bet pocket officetmobile launch late p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>technologie</td>\n",
       "      <td>oneplus   spec comparison chart   vs   Pro vs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>technologie</td>\n",
       "      <td>friend fear lose mobilespeople dependent mobil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                              words\n",
       "0  technologie  game firm face tough futureUK video game firm ...\n",
       "1  technologie  California set fine spywarethe maker computer ...\n",
       "2  technologie  tmobile bet pocket officetmobile launch late p...\n",
       "3  technologie  oneplus   spec comparison chart   vs   Pro vs ...\n",
       "4  technologie  friend fear lose mobilespeople dependent mobil..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up text into a simple collection of words\n",
    "df['words'] = df['text'].apply(clean_text)\n",
    "df = df.drop(['text'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e22dcdd-1706-4ee5-8264-795fe8580295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep for model building\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e93c5ff9-e2c0-4bc2-a114-3c96bf412b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,) (800,) (206,) (206,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9s/k8cgl3rd2xl_7_pg8yrvgr_80000gn/T/ipykernel_10251/3887158823.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_test = df_test.append( df[df['label'] == 'other'] )\n"
     ]
    }
   ],
   "source": [
    "# Build the training set.  Per instructions, documents marked 'other' are excluded for training,\n",
    "# but we'll include them all in the test set\n",
    "df_train, df_test = train_test_split(df[df['label'] != 'other'], test_size=0.2, random_state=20050723+20080710)\n",
    "\n",
    "df_test = df_test.append( df[df['label'] == 'other'] )\n",
    "\n",
    "X_train, y_train = df_train['words'], df_train['label']\n",
    "X_test, y_test = df_test['words'], df_test['label']\n",
    "\n",
    "df_other = df[df['label'] == 'other']\n",
    "X_other, y_other = df_other['words'], df_other['label']\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75047921-d91c-4191-9598-04f941adc166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use a Naive Bayes classifier to make predictions.  The inputs to the model itself will\n",
    "# come from applying TF-IDF on the data: identifying how relevant specific words are to the various\n",
    "# document classes.  \n",
    "# As part of cleaning up the input text we explicitly removed stop words.  TF-IDF would de-emphasize\n",
    "# these words for the training data automatically, but removing them also creates a minor speed boost,\n",
    "# perhaps important if we later trained with more data.\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02540ca4-0843-4500-9415-f940fc60eb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9368932038834952\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       1.00      0.91      0.95        22\n",
      "entertainment       0.96      0.96      0.96        24\n",
      "         food       1.00      1.00      1.00        14\n",
      "     graphics       0.96      1.00      0.98        24\n",
      "   historical       0.90      1.00      0.95        19\n",
      "      medical       0.95      1.00      0.97        18\n",
      "        other       0.00      0.00      0.00         6\n",
      "     politics       0.71      1.00      0.83        15\n",
      "        space       1.00      0.86      0.93        22\n",
      "        sport       0.95      1.00      0.97        19\n",
      "  technologie       0.96      0.96      0.96        23\n",
      "\n",
      "     accuracy                           0.94       206\n",
      "    macro avg       0.85      0.88      0.86       206\n",
      " weighted avg       0.92      0.94      0.92       206\n",
      "\n",
      "[[20  0  0  0  0  0  0  2  0  0  0]\n",
      " [ 0 23  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0 14  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 24  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 19  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 18  0  0  0  0  0]\n",
      " [ 0  1  0  1  0  1  0  2  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 15  0  0  0]\n",
      " [ 0  0  0  0  2  0  0  1 19  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 19  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0 22]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alastair/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/alastair/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/alastair/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# first show performance without considering 'other' class\n",
    "# We'll get warnings about not being able to compute F-1 score etc, since we're providing\n",
    "# examples with the 'other' class but not having trained with it.\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "y_pred = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbc357e0-ae30-4005-9f2e-7c91b3c28064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum difference between max probability and mean of all: 0.08609888182706918\n"
     ]
    }
   ],
   "source": [
    "# This model needs to account for when it can't confidently assign a class to a given document, so we can't\n",
    "# just call MultinomialNB.predict(): it will always make a class prediction.  The softmax inside the prediction\n",
    "# step will sum everything to 1, so there'll always be a maximum value for a specific class, but we assume that\n",
    "# if it's a confident prediction the other probabilities will be *much* smaller.  Conversely, we believe that if\n",
    "# it's not a confident prediction then all probabilities will be fairly close to each other: it's not strongly\n",
    "# opinionated about any class.\n",
    "\n",
    "# So, let's quantify a threshold for that.  For some of these 'other' samples, let's find the maximum delta between the\n",
    "# maximum class probability and the average of all class probabilities.  The threshold for making a class prediction\n",
    "# would be somewhere above that.\n",
    "\n",
    "# In a more robust environment, It'd be nice to have access to more examples of unrecognized documents that we'd expect to see.\n",
    "\n",
    "X_other_tfidf = tfidf_vectorizer.transform(X_other)\n",
    "y_pred_proba = nb_classifier.predict_proba(X_other_tfidf)\n",
    "\n",
    "max_mean_probas = []\n",
    "for probas in y_pred_proba:\n",
    "    max_mean_probas.append((np.max(probas), np.mean(probas)))\n",
    "\n",
    "other_threshold = np.max(list(map(lambda x: x[0]-x[1], max_mean_probas)))\n",
    "print(f\"Maximum difference between max probability and mean of all: {other_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00d5ef4e-1e66-4c3f-8bc1-652b21e2be0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9174757281553398\n",
      "Difference from previous model: -0.0194\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       1.00      0.91      0.95        22\n",
      "entertainment       1.00      0.92      0.96        24\n",
      "         food       1.00      1.00      1.00        14\n",
      "     graphics       1.00      0.75      0.86        24\n",
      "   historical       1.00      0.95      0.97        19\n",
      "      medical       1.00      1.00      1.00        18\n",
      "        other       0.32      1.00      0.48         6\n",
      "     politics       0.83      1.00      0.91        15\n",
      "        space       1.00      0.77      0.87        22\n",
      "        sport       1.00      1.00      1.00        19\n",
      "  technologie       0.96      0.96      0.96        23\n",
      "\n",
      "     accuracy                           0.92       206\n",
      "    macro avg       0.92      0.93      0.91       206\n",
      " weighted avg       0.96      0.92      0.93       206\n",
      "\n",
      "[[20  0  0  0  0  0  0  2  0  0  0]\n",
      " [ 0 22  0  0  0  0  1  0  0  0  1]\n",
      " [ 0  0 14  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 18  0  0  6  0  0  0  0]\n",
      " [ 0  0  0  0 18  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0 18  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  6  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 15  0  0  0]\n",
      " [ 0  0  0  0  0  0  5  0 17  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 19  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0 22]]\n"
     ]
    }
   ],
   "source": [
    "# However, when running this model, we do manage to identify all the uncategorizable 'other'\n",
    "# documents, but at a penalty: a handful of classes (entertainment, graphics, historical, space)\n",
    "# have nontrivial drops in recall, as several of those documents get misclassified as 'other'.\n",
    "# In the end, overall accuracy drops almost 2%, with perfect recall for the 'other' class, but much\n",
    "# worse precision.\n",
    "\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "y_pred_proba = nb_classifier.predict_proba(X_test_tfidf)\n",
    "y_pred = []\n",
    "\n",
    "for probas in y_pred_proba:\n",
    "    if np.max(probas) - np.mean(probas) > other_threshold:\n",
    "        max_label = max(zip(probas, nb_classifier.classes_))[1]\n",
    "        y_pred.append(max_label)\n",
    "    else:\n",
    "        y_pred.append('other')\n",
    "\n",
    "accuracy_other = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy_other}')\n",
    "print(f'Difference from previous model: {accuracy_other - accuracy:0.04f}')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68b52222-da6e-4042-99ca-30b670293401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.935 0.955 0.93  0.98  0.97 ]\n",
      "Mean CV Accuracy: 0.9540000000000001\n",
      "Standard Deviation of CV Accuracy: 0.019339079605813683\n"
     ]
    }
   ],
   "source": [
    "# In advance of training a final model on the entire dataset, again excluding the 'other' documents,\n",
    "# let's explore how well the dataset generalizes using cross-validation.  The standard deviation\n",
    "# between the various folds is less than 0.02, which is pretty stable.\n",
    "\n",
    "df_final = df[df['label'] != 'other']\n",
    "X, y = df_final['words'], df_final['label']\n",
    "X_tfidf = tfidf_vectorizer.transform(X)\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "cv_scores = cross_val_score(nb_classifier, X_tfidf, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(f'Cross-Validation Accuracy Scores: {cv_scores}')\n",
    "print(f'Mean CV Accuracy: {cv_scores.mean()}')\n",
    "print(f'Standard Deviation of CV Accuracy: {cv_scores.std()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c25bdc24-5ee4-42d5-ac39-c310e396396b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a final model on the full dataset\n",
    "# Future steps we'd want to explore:\n",
    "# - Training on a larger dataset: 1000 examples across ten classes is a small training set for this kind of problem\n",
    "# - Using a larger example set of 'other' documents to explore other ways to identify entities entirely out of the training set distribution\n",
    "# - Testing with not just a train/test set, but a third validation set: after any other hyperparameters are adjusted (for example,\n",
    "#   the threshold for 'other' class predictions), train a final model on all train/test, and check the score on validation.\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "417f99a8-0fa5-4821-85c3-4dd3367ec8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export trained model for use by the service\n",
    "# We are going to use the other_threshold we computed before, however this value has been computed for the\n",
    "# training set, 80% of this full set.  In practice we would want to either:\n",
    "# - Keep this threshold associated with the model trained only on the training set, not this full dataset\n",
    "# - Perform holdout studies to see how much this threshold changes on various training set sizes, if at all.\n",
    "#   It would be nice to see if this threshold doesn't vary much as training data sizes grow.\n",
    "\n",
    "import joblib\n",
    "out_dir = \"output\"\n",
    "model_file = \"tfidf_model.pkl\"\n",
    "joblib.dump(nb_classifier, os.path.join(out_dir, model_file))\n",
    "\n",
    "vectorizer_file = \"tfidf_vectorizer.pkl\"\n",
    "joblib.dump(tfidf_vectorizer, os.path.join(out_dir, vectorizer_file))\n",
    "\n",
    "configuration = {\n",
    "    \"model_file\": model_file,\n",
    "    \"vectorizer_file\": vectorizer_file,\n",
    "    \"other_threshold\": other_threshold\n",
    "}\n",
    "\n",
    "config_file = \"model_config.json\"\n",
    "with open(os.path.join(out_dir, config_file), 'w', encoding='utf-8') as f:\n",
    "    print(json.dumps(configuration, indent=4), file=f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee68e7e-4ed5-4a0a-bf87-652603d57ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
